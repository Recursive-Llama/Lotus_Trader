# Position Backup & Restore Tools

Tools for handling positions during system restarts.

## Two Approaches

### Approach 1: Reinsert as Fresh Signals (Recommended)

**`reinsert_positions_as_signals.py`** - Export contracts, delete positions, reinsert as social signals

This is the **recommended approach** because:
- Positions go through the full normal flow (social signal → decision maker → position creation → backfill)
- Fresh state initialization (empty `features`, proper `status` based on `bars_count`)
- Automatic backfill triggered by Decision Maker
- Learning context preserved (entry_context, curator_sources)

**Usage:**
```bash
# Dry run (see what would happen)
python tools/reinsert_positions_as_signals.py --status active --dry-run

# Actually do it (with auto-processing)
python tools/reinsert_positions_as_signals.py --status active --auto-process

# Or let scheduled job process signals
python tools/reinsert_positions_as_signals.py --status active
```

**What it does:**
1. Extracts unique token contracts/tickers from positions
2. Deletes those positions
3. Creates `social_lowcap` strands (as if someone mentioned them)
4. Optionally triggers learning system to process them immediately
5. Decision Maker creates fresh positions and triggers backfill

---

### Approach 2: Direct Position Import (Legacy)

**`export_positions.py`** + **`import_positions.py`** - Direct position backup/restore

Use this if you want to preserve exact position state (execution history, features, etc.).

## Quick Start

### 1. Export Positions (Before Wipe)

Export all active positions:
```bash
python tools/export_positions.py --status active --output my_positions_backup.json
```

Export all positions (any status):
```bash
python tools/export_positions.py --output all_positions_backup.json
```

Export by timeframe:
```bash
python tools/export_positions.py --status active --timeframe 1h --output active_1h_backup.json
```

### 2. Wipe Database

Do your database wipe/restart...

### 3. Import Positions (After Restart)

Import all positions:
```bash
python tools/import_positions.py my_positions_backup.json
```

Dry run (see what would be imported):
```bash
python tools/import_positions.py my_positions_backup.json --dry-run
```

Skip positions that already exist:
```bash
python tools/import_positions.py my_positions_backup.json --skip-existing
```

## What Gets Exported/Imported

**Exported:**
- All position columns (token info, quantities, prices, P&L, features JSONB, etc.)
- Full `features` JSONB (uptrend_engine_v4, ta, geometry, pm_execution_history, etc.)

**Not Exported (regenerated):**
- `id` - New UUID generated on import
- `created_at`, `updated_at` - Set to current time on import

**Unique Constraint:**
- Positions are uniquely identified by `(token_contract, token_chain, timeframe)`
- If a position already exists, use `--skip-existing` to avoid errors

## Example Workflow

```bash
# 1. Export active positions
python tools/export_positions.py --status active --output active_backup.json

# 2. (Do your database wipe/restart)

# 3. Import them back
python tools/import_positions.py active_backup.json

# 4. Verify
# Check your database to confirm positions were restored
```

## Notes

- **Features JSONB**: All PM state (episodes, execution history, trim pools, etc.) is preserved
- **Learning Data**: This only backs up positions. Learning lessons/overrides are separate
- **Price Data**: Price/OHLC data is regenerated by bootstrap system
- **Regime Drivers**: Regime driver positions are auto-created by bootstrap, no need to backup

